# Synthetic Personas

## Overview
The Synthetic Personas tool is designed to assist survey methodologists and researchers in testing survey questions and improving response quality. By leveraging synthetic personas, researchers can refine survey questions more efficiently, minimizing the need for extensive field testing and reducing costs and resource demands. This tool is not meant to replace human testing but to complement it, serving as an early-stage evaluator to identify potential issues before live deployment.

Future enhancements will integrate **Big Five personality data** with **demographic information**, allowing researchers to request survey respondents based on location and psychological traits. Another planned feature is a **GPT-based model** that generates survey responses using these enhanced synthetic personas. Researchers will also have the option to upload a **personality and demographic profile** to any compatible LLM, enabling it to adjust responses based on psychological and geographic characteristics. This approach ensures synthetic personas can be seamlessly incorporated into survey design workflows, providing precise and representative testing.

The Synthetic Personas GPT is available at: [Synthetic Personas GPT](https://chatgpt.com/g/g-67a80d375e1c819186b960f5e60f9b9d-synthetic-personas)

---

## Synthetic Personas and Big Five Personality Traits in Surveys

### **What Are Synthetic Personas?**
Synthetic personas are artificially generated user profiles that simulate real human behaviors and characteristics. Unlike traditional personas, which rely on qualitative research, synthetic personas are data-driven and generated using AI, statistical models, and large datasets. Their primary purpose is to represent diverse user types and predict behaviors in various contexts.

Synthetic personas are widely used in UX design, marketing, AI training, and behavioral simulations. They provide a scalable, privacy-conscious way to explore user experiences and anticipate interactions with systems, products, or services.

---

### **Big Five Personality Traits and Their Role in Synthetic Personas**
The **Big Five personality model**, also known as **OCEAN**, is one of the most widely accepted frameworks for understanding human personality. The five traits include:
- **Openness to Experience** ‚Äì Creativity, curiosity, and preference for new experiences.
- **Conscientiousness** ‚Äì Organization, responsibility, and self-discipline.
- **Extraversion** ‚Äì Sociability, assertiveness, and outgoing nature.
- **Agreeableness** ‚Äì Compassion, empathy, and cooperation.
- **Neuroticism** ‚Äì Emotional stability and the tendency to experience negative emotions.

Incorporating these traits into synthetic personas enhances their psychological realism and behavioral diversity. Assigning different Big Five trait levels to synthetic personas allows researchers to better predict how different personality types will respond to surveys, products, or content.

---

### **How Big Five Data Shapes Synthetic Personas**
Big Five personality data can be collected from:
- Psychometric assessments and personality questionnaires.
- Behavioral data analysis (e.g., social media activity, digital behavior patterns).
- User interaction history and feedback.

Machine learning models can analyze this data and cluster users into different personality segments. These segments serve as a foundation for generating synthetic personas.

For example:
- A persona with **high Openness and low Neuroticism** may be adventurous and open to new experiences, making them ideal for targeting early adopters.
- A persona with **high Conscientiousness and high Agreeableness** may prefer structured, cooperative environments, making them suitable for team-based projects.

Using personality-driven personas improves personalization, refines engagement strategies, and enhances behavioral research.

---

## AI-Generated Survey Responses and Their Impact on Research

### **The Use of AI in Survey Participation**
When users are paid to complete surveys, some turn to AI tools such as ChatGPT to generate their responses. Academic researchers have noted that AI-generated answers often appear more polished, contain fewer typos, and lack the snark or emotional nuance typical of human responses. 

A study by Janet Xu, Simone Zhang, and AJ Alvero examined AI use among Prolific survey participants. They found that nearly one-third of respondents admitted to using LLMs for survey work. The primary reason was difficulty in expressing thoughts clearly. While some participants viewed AI as a helpful tool, others avoided it due to concerns about authenticity and validity.

AI-generated responses may affect research outcomes in several ways:
- **Bias in Public Opinion Data**: Differences in AI use among demographic groups could introduce distortions in survey results.
- **Loss of Emotional Nuance**: AI-generated responses tend to be neutral and detached, reducing the richness and variability of human expression.
- **Risk of Homogenization**: Over-reliance on AI-generated responses may lead to less diversity in viewpoints and a flattening of perspectives.

Researchers have identified ways to mitigate AI‚Äôs influence on survey data:
- Clearly instructing participants not to use AI.
- Implementing technical measures, such as blocking copy-pasting.
- Offering alternative input methods, such as voice recordings.
- Improving survey design to make questions more engaging and less ambiguous.

Xu notes that the increasing use of AI in surveys requires scholars and researchers to scrutinize their data more carefully. While AI can be beneficial for refining thoughts, its unchecked use may dilute the authenticity of human responses and lead to misleading conclusions in social and behavioral research.

---

## Using Synthetic Personas and Big Five Data in Surveys

### **1. Generating Synthetic Personas from Survey Data**
Survey responses measuring the Big Five traits can serve as input for generating synthetic personas. Researchers can segment respondents based on their personality traits and simulate new personas that mirror the behavioral tendencies of these clusters.

**Example:**
- A company conducts a survey to understand customer preferences.
- Respondents are grouped into personality clusters.
- AI models generate synthetic personas that reflect each cluster‚Äôs behavioral traits.

---

### **2. Testing Survey Content with Synthetic Personas**
Synthetic personas can be used to predict how different personality types might interpret or respond to survey questions. Researchers can:
- Detect biased or confusing questions.
- Ensure questions are engaging for different personality types (e.g., structured for conscientious users, open-ended for those high in Openness).
- Optimize survey structure to improve response rates.

---

### **3. Predicting Behavioral Patterns in Survey Responses**
Synthetic personas can simulate responses to new surveys before their deployment. By aligning behavioral predictions with Big Five data, researchers can anticipate:
- Response styles based on personality (e.g., extraverts providing longer responses to open-ended questions).
- Segment-wide response patterns, allowing for better-balanced question structures.

---

## Conclusion
Synthetic personas represent a powerful tool for enhancing survey research. However, the increasing prevalence of AI-generated survey responses introduces new challenges for researchers. While AI can aid in expression, it may distort public opinion data, dilute response diversity, and introduce biases.

By integrating **Big Five personality traits** and demographic data, synthetic personas provide realistic behavioral simulations, improve survey design, and enable researchers to test survey questions more efficiently while preserving user privacy. Future developments will continue refining their predictive capabilities, ensuring greater accuracy and applicability in behavioral research.



## Datasets

### **Big Five Personality Test Dataset (1M Responses) ‚Äì Kaggle**  

üìå **Dataset Link:** [Big Five Personality Test (1M Responses)](https://www.kaggle.com/datasets/tunguz/big-five-personality-test)  

#### **üîç About the Dataset**  
This dataset contains **1,015,342 responses** to a **50-item Big Five personality questionnaire** collected by **Open Psychometrics**. It provides a large-scale dataset for analyzing personality traits using the **OCEAN model** (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism).  

#### **üìä Dataset Overview:**  
- **Source:** Open Psychometrics  
- **Number of Responses:** 1,015,342  
- **Questions:** 50 personality items measuring **Big Five personality traits**  
- **Collected Data:** Participants' answers to personality survey questions  

#### **üß† What Can You Do with This Dataset?**  
**Analyze Personality Distributions** ‚Äì Explore how different personality traits correlate.  
**Develop AI-Powered Personality Models** ‚Äì Train models to predict behaviors based on Big Five scores.  
**Generate Synthetic Personas** ‚Äì Use real-world Big Five data to create **AI-driven user profiles**.  
**Study Demographic Differences in Personality** ‚Äì Examine personality variations across different population segments.  
**Optimize User Experience & Survey Design** ‚Äì Improve targeting and personalization in research and marketing.  

üîó **Download and Explore the Dataset Here:** [Big Five Personality Test ‚Äì Kaggle](https://www.kaggle.com/datasets/tunguz/big-five-personality-test)  


### BFI Dataset

### **Understanding the Columns in the `bfi` Dataset (Big Five Inventory)**
The **`bfi` dataset** in the `psych` package contains responses to the **Big Five Personality Inventory (BFI-25)**, where participants rate themselves on various personality-related statements.

---

### **üìå Column Breakdown**
The dataset consists of **25 personality trait questions**, along with **demographic variables (gender, education, age).** The **personality trait questions** are grouped into **five factors**:  
- **A (Agreeableness)**  
- **C (Conscientiousness)**  
- **E (Extraversion)**  
- **N (Neuroticism)**  
- **O (Openness to Experience)**  

| Column | Trait        | Description |
|---------|------------|------------|
| **A1 - A5** | **Agreeableness** | Measures empathy, cooperation, and kindness. |
| **C1 - C5** | **Conscientiousness** | Measures organization, self-discipline, and dependability. |
| **E1 - E5** | **Extraversion** | Measures sociability, assertiveness, and energy levels. |
| **N1 - N5** | **Neuroticism** | Measures emotional stability vs. anxiety and mood swings. |
| **O1 - O5** | **Openness to Experience** | Measures creativity, curiosity, and willingness to try new things. |
| **gender** | **Demographic** | 1 = Male, 2 = Female |
| **education** | **Demographic** | Level of education (missing values = NA). |
| **age** | **Demographic** | Age of respondent. |

---

### **üìä Example Interpretation**
| ID     | A1 | A2 | A3 | A4 | A5 | C1 | C2 | C3 | C4 | C5 | E1 | E2 | E3 | E4 | E5 | N1 | N2 | N3 | N4 | N5 | O1 | O2 | O3 | O4 | O5 | Gender | Education | Age |
|--------|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|--------|-----------|----|
| 61617  | 2  | 4  | 3  | 4  | 4  | 2  | 3  | 3  | 4  | 4  | 3  | 3  | 3  | 4  | 4  | 3  | 4  | 2  | 2  | 3  | 3  | 6  | 3  | 4  | 3  | 1      | NA        | 16 |
| 61618  | 2  | 4  | 5  | 2  | 5  | 5  | 4  | 4  | 3  | 4  | 1  | 1  | 6  | 4  | 3  | 3  | 3  | 3  | 5  | 5  | 4  | 2  | 4  | 3  | 3  | 2      | NA        | 18 |
| 61620  | 5  | 4  | 5  | 4  | 4  | 4  | 5  | 4  | 2  | 5  | 2  | 4  | 4  | 4  | 5  | 4  | 5  | 4  | 2  | 3  | 4  | 2  | 5  | 5  | 2  | 2      | NA        | 17 |

Each personality trait is rated on a **Likert scale** (usually **1 to 6**), where:  
1Ô∏è‚É£ **Low score** = Less of that trait (e.g., low extraversion means more introverted).  
6Ô∏è‚É£ **High score** = More of that trait (e.g., high openness means very curious & creative).  

---

### **üìå Summary**
- **A1 - A5** ‚Üí Agreeableness üß° *(Kindness, empathy, cooperation)*
- **C1 - C5** ‚Üí Conscientiousness ‚úÖ *(Self-discipline, reliability)*
- **E1 - E5** ‚Üí Extraversion üéâ *(Sociability, energy, talkativeness)*
- **N1 - N5** ‚Üí Neuroticism üò® *(Anxiety, emotional instability)*
- **O1 - O5** ‚Üí Openness üåé *(Creativity, willingness to try new experiences)*
- **gender** ‚Üí 1 = Male, 2 = Female  
- **education** ‚Üí Level of education (some missing data = `NA`)  
- **age** ‚Üí Age of respondent  

Would you like to analyze the **trait distributions** or **correlate traits with demographics**? üöÄ


## Papers

### Reference Entry for GitHub

Shrestha, P., Krpan, D., & Binbaz, M. S. (2024). *Beyond WEIRD: Can synthetic survey participants substitute for humans in global policy research?* *Behavioral Science & Policy*. OnlineFirst. [https://doi.org/10.1177/23794607241311793](https://doi.org/10.1177/23794607241311793)

**Summary:**  
This study explores the feasibility of using large language models (LLMs), specifically GPT-4, to create synthetic survey participants that mimic human responses in global policy research. The researchers compared human and synthetic responses across three policy domains‚Äîsustainability, financial literacy, and female labor force participation‚Äîin both WEIRD (Western, Educated, Industrialized, Rich, Democratic) and non-WEIRD nations, including Saudi Arabia and the UAE. The study found that synthetic participants' responses were reasonably aligned with human responses but exhibited variations, particularly in non-WEIRD samples. Synthetic participants also tended to display more progressive views and higher financial literacy than their human counterparts. The findings suggest that synthetic participants can be useful for preliminary testing in policy research but should be used cautiously in advanced policy development due to potential biases.


##  AI-Generated Survey Responses Could Make Research Less Accurate (And a Lot Less Interesting)

Note Bien: **Note on the Value of Synthetic Personas in Survey Research**  

The growing use of **AI-generated responses in paid surveys** raises concerns about data integrity, as financial incentives drive participants to prioritize speed over authenticity. Studies show that many respondents on platforms like **Prolific and Amazon Mechanical Turk** use AI tools to complete surveys quickly, leading to **homogenized responses, reduced emotional nuance, and potential biases** in public opinion data.  

**Synthetic personas offer a compelling alternative** to human participants in such research. Unlike paid survey respondents, **synthetic personas do not have the incentive to rush through surveys** for financial gain, ensuring that responses remain **consistent, unbiased, and free from AI-generated distortions**. Additionally, research indicates that **synthetic personas exhibit a high correlation with human responses**, making them a viable tool for early-stage testing and methodological refinement.  

By integrating **Big Five personality traits and demographic data**, synthetic personas can be designed to closely mimic real-world populations while eliminating the distortions introduced by AI-assisted responses in paid surveys. This makes them particularly valuable for **survey pretesting, behavioral simulations, and hypothesis validation**, ultimately improving data quality and research reliability.

## The Stanford Graduate School of Business study

A study from **Stanford Graduate School of Business** highlights how **AI-generated survey responses** could impact research accuracy, particularly in paid surveys. When researchers need participants for large-scale studies, they often turn to **crowdsourcing platforms like Prolific and Amazon Mechanical Turk**, where users are paid in cash or gift cards to provide responses. This financial incentive **increases the likelihood of AI usage**, as some participants prioritize speed over authenticity.  

The study, led by **Janet Xu, Simone Zhang, and AJ Alvero**, surveyed 800 Prolific users‚Äîwho had all taken paid surveys‚Äîand found that **nearly one-third admitted to using AI tools like ChatGPT** to assist in answering survey questions. However, these figures only account for those **willing to disclose their AI usage**, suggesting that the actual percentage may be even higher.  

Key findings:  
- **AI-generated responses tend to be polished, contain fewer typos, and lack emotional nuance** compared to human answers.  
- **Financial incentives encourage quick completion**, increasing the temptation to use AI for efficiency.  
- **Bias in public opinion data** may arise as AI-generated responses differ from human ones.  
- **Homogenization of perspectives** could distort research conclusions, especially on sensitive topics like race and politics.  

The study suggests that **AI interference in survey data is growing**, and researchers must take steps to **design clearer questions, discourage AI use, and implement technical restrictions** such as disabling copy-paste functions.  

Read more: [Stanford GSB - AI-Generated Survey Responses](https://www.gsb.stanford.edu/insights/ai-generated-survey-responses-could-make-research-less-accurate-lot-less-interesting)

**Large Language Models for Behavioral Economics: Synthetic Mental Models and Data Generalization**

Jabarian, Brian, Large Language Models for Behavioral Economics: Synthetic Mental Models and Data Generalization (June 08, 2024). Available at SSRN: [https://ssrn.com/abstract=4880894] or [http://dx.doi.org/10.2139/ssrn.4880894]

**Summary**
The paper ‚ÄúLarge Language Models for Behavioral Economics: Synthetic Mental Models and Data Generalization‚Äù by Brian Jabarian explores how researchers can leverage Large Language Models (LLMs) to generate synthetic data for replicating and extending behavioral economics experiments. It introduces the concept of endowing AI agents with multi-context identities and mental models to ensure scientific robustness in simulating human-like decision-making. By assigning AI agents specific worldviews, social contexts, and psychological factors, the study examines how well LLM-generated data can achieve weak generalization (replicating known human behaviors) and strong generalization (extending findings to novel populations). The research highlights GPT-3.5 as the most accurate model for mimicking human decisions but acknowledges concerns like model collapse due to synthetic data reliance. The paper suggests reinforcement learning and prompt engineering as potential solutions to enhance the reliability and applicability of AI-driven behavioral simulations.

**Abstract**
In this article, we focus on how researchers can leverage Large Language Models (LLMs) to generate synthetic data to replicate and explore the generalization of established results to new synthetic environments and populations. We discuss a key condition ensuring such a generation of synthetic data with simulated Artificial Intelligence (AI) agents is scientifically robust: endowing AI agents with multicontext identity and mental models and ensuring that the synthetic observations are independent. We first outline the infrastructure required to embody multi-context identities and mental models to LLMs agents. We then focus on case studies.

**UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design**

**Summary**
The paper titled ‚ÄúUXAgent: An LLM Agent-Based Usability Testing Framework for Web Design‚Äù introduces a novel system designed to assist User Experience (UX) researchers in evaluating web designs through simulated usability testing. Traditional usability testing often encounters challenges such as inflexibility in iterating study designs and difficulties in recruiting suitable participants. To address these issues, the authors propose UXAgent, which leverages Large Language Model-simulated Agents (LLM-Agents) to emulate user interactions with websites.

**Abstract**
Usability testing is a fundamental yet challenging (e.g., inflexible to iterate the study design flaws and hard to recruit study participants) research method for user experience (UX) researchers to evaluate a web design. Recent advances in Large Language Model-simulated Agent (LLM-Agent) research inspired us to design UXAgent to support UX researchers in evaluating and reiterating their usability testing study design before they conduct the real human subject study. Our system features an LLM-Agent module and a universal browser connector module so that UX researchers can automatically generate thousands of simulated users to test the target website. The results are shown in qualitative (e.g., interviewing how an agent thinks ), quantitative (e.g., # of actions), and video recording formats for UX researchers to analyze. Through a heuristic user evaluation with five UX researchers, participants praised the innovation of our system but also expressed concerns about the future of LLM Agent-assisted UX study.
[https://arxiv.org/abs/2502.12561]

**LLM Generated Persona is a Promise with a Catch**

**Summary**
Large Language Models (LLMs) are increasingly being used to generate synthetic personas‚Äîdetailed fictional profiles‚Äîto simulate human behaviors and opinions. These ‚Äúsilicon samples‚Äù could revolutionize areas like social science, political forecasting, marketing, and design. But there‚Äôs a major catch: LLM-generated personas are systematically biased and often diverge significantly from real-world population data.

**Abstact**
The use of large language models (LLMs) to simulate human behavior has gained significant attention, particularly through personas that approximate individual characteristics. Persona-based simulations hold promise for transforming disciplines that rely on population-level feedback, including social science, economic analysis, marketing research, and business operations. Traditional methods to collect realistic persona data face significant challenges. They are prohibitively expensive and logistically challenging due to privacy constraints, and often fail to capture multi-dimensional attributes, particularly subjective qualities. Consequently, synthetic persona generation with LLMs offers a scalable, cost-effective alternative. However, current approaches rely on ad hoc and heuristic generation techniques that do not guarantee methodological rigor or simulation precision, resulting in systematic biases in downstream tasks. Through extensive large-scale experiments including presidential election forecasts and general opinion surveys of the U.S. population, we reveal that these biases can lead to significant deviations from real-world outcomes. Our findings underscore the need to develop a rigorous science of persona generation and outline the methodological innovations, organizational and institutional support, and empirical foundations required to enhance the reliability and scalability of LLM-driven persona simulations. 
[https://arxiv.org/abs/2503.16527]

## Links'
[https://outset.ai/](https://outset.ai/)

[ https://www.subconscious.ai/]( https://www.subconscious.ai/)

[ https://www.syntheticusers.com](https://www.syntheticusers.com)

[ https://vurvey.com/](https://vurvey.com/)

[ https://www.yabble.com/](https://www.yabble.com/)

[https://www.evidenza.ai](https://www.evidenza.ai)



